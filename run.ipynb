{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from time import sleep\n",
    "\n",
    "import numpy as np\n",
    "import pynvml\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import os\n",
    "\n",
    "pynvml.nvmlInit()\n",
    "last_task_t = [0] * 10\n",
    "\n",
    "\n",
    "def get_free_MB(i):\n",
    "    handle = pynvml.nvmlDeviceGetHandleByIndex(i)\n",
    "    return pynvml.nvmlDeviceGetMemoryInfo(handle).free / 1024 / 1024\n",
    "\n",
    "\n",
    "def get_ps_num(i):\n",
    "    handle = pynvml.nvmlDeviceGetHandleByIndex(i)\n",
    "    gpu_ps = pynvml.nvmlDeviceGetComputeRunningProcesses(handle)\n",
    "    return len(gpu_ps)\n",
    "\n",
    "\n",
    "def get_avail_gpu(size=10000):\n",
    "    num = pynvml.nvmlDeviceGetCount()\n",
    "    free = []\n",
    "    for _ in range(60):\n",
    "        sleep(1)\n",
    "        free.append([get_free_MB(i) for i in range(num)])\n",
    "    free = np.array(free).T.tolist()\n",
    "    avail_gpus = []\n",
    "    for i in range(num):\n",
    "        if i == 3:\n",
    "            continue\n",
    "        if min(free[i]) > size and time.time() - last_task_t[i] > 600:\n",
    "            avail_gpus.append(i)\n",
    "    return avail_gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = []\n",
    "# for tol in [30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95]:\n",
    "#     tasks.append((f\"wfgan_tol{tol}\", \"wfgan\"))\n",
    "for gan in [1, 3, 5, 7, 9]:\n",
    "    for tol in [30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95]:\n",
    "        tasks.append((f\"switch_gan{gan:02d}_tol{tol}_front{10-gan:02d}\", \"switch_gan_front\"))\n",
    "# for p in [\"equal\", \"random\"]:\n",
    "#     for tamaraw in range(2):\n",
    "#         for regulartor in range(2):\n",
    "#             for front in range(2):\n",
    "#                 for wfgan in range(2):\n",
    "#                     if tamaraw + regulartor + front + wfgan > 0:\n",
    "#                         name = f\"switch_{p}\"\n",
    "#                         if front:\n",
    "#                             name += \"_front\"\n",
    "#                         if wfgan:\n",
    "#                             name += \"_wfgan\"\n",
    "#                         if tamaraw:\n",
    "#                             name += \"_tamaraw\"\n",
    "#                         if regulartor:\n",
    "#                             name += \"_regulartor\"\n",
    "#                         tasks.append((name, f\"switch_{p}\"))\n",
    "\n",
    "\n",
    "# tasks.extend([(name, \"base\") for name in [\"undefend\", \"front\", \"tamaraw\", \"wfgan\", \"regulartor\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avail_gpus = []\n",
    "for task, note in tqdm(tasks):\n",
    "    log_dir = f\"run/20240308{note}/RF/train_undefend_d{task}\"\n",
    "    if os.path.exists(log_dir):\n",
    "        print(f\"skip {task}\")\n",
    "        continue\n",
    "    while not avail_gpus:\n",
    "        avail_gpus = get_avail_gpu()\n",
    "\n",
    "    gpu = avail_gpus.pop()\n",
    "    subprocess.Popen(\n",
    "        f\"python train.py --train {task} --note {note} -g {gpu}\",\n",
    "        shell=True,\n",
    "        stdout=subprocess.DEVNULL,\n",
    "    )\n",
    "    last_task_t[gpu] = time.time()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wfp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
