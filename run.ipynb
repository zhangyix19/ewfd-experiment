{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from time import sleep\n",
    "\n",
    "import numpy as np\n",
    "import pynvml\n",
    "from tqdm import tqdm\n",
    "\n",
    "pynvml.nvmlInit()\n",
    "\n",
    "\n",
    "def get_free_MB(i):\n",
    "    handle = pynvml.nvmlDeviceGetHandleByIndex(i)\n",
    "    return pynvml.nvmlDeviceGetMemoryInfo(handle).free / 1024 / 1024\n",
    "\n",
    "\n",
    "def get_avail_gpu(size=10000):\n",
    "    num = pynvml.nvmlDeviceGetCount()\n",
    "    free = []\n",
    "    for _ in range(50):\n",
    "        sleep(0.4)\n",
    "        free.append([get_free_MB(i) for i in range(num)])\n",
    "    free = np.array(free).T.tolist()\n",
    "    for i in range(num):\n",
    "        if min(free[i]) > size:\n",
    "            return i\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "note = \"switch_gan_front\"\n",
    "tasks = []\n",
    "\n",
    "for gan in [2, 4, 6, 8, 10]:\n",
    "    for tol in [30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95]:\n",
    "        tasks.append(\n",
    "            f\"switch_gan{gan:02d}_tol{tol}_front{10-gan:02d}\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 1/70 [00:20<23:19, 20.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python train.py --train switch_gan02_tol30_front08 --note switch_gan_front -g 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 2/70 [00:40<22:55, 20.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python train.py --train switch_gan02_tol35_front08 --note switch_gan_front -g 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 3/70 [01:00<22:32, 20.18s/it]  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python train.py --train switch_gan02_tol40_front08 --note switch_gan_front -g 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training:  54%|█████▍    | 215/400 [12:09<10:28,  3.39s/it]\n",
      "training:  61%|██████    | 243/400 [13:38<08:49,  3.37s/it]\n",
      "  6%|▌         | 4/70 [15:13<6:23:52, 348.97s/it] 2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python train.py --train switch_gan02_tol45_front08 --note switch_gan_front -g 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 5/70 [15:33<4:09:38, 230.44s/it] 2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python train.py --train switch_gan02_tol50_front08 --note switch_gan_front -g 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training:  68%|██████▊   | 273/400 [14:34<06:46,  3.20s/it]\n",
      "training:  57%|█████▋    | 227/400 [10:19<07:52,  2.73s/it]\n",
      "training:  59%|█████▉    | 237/400 [10:46<07:24,  2.73s/it]\n",
      "  9%|▊         | 6/70 [26:44<6:45:26, 380.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python train.py --train switch_gan02_tol55_front08 --note switch_gan_front -g 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 7/70 [27:04<4:35:35, 262.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python train.py --train switch_gan02_tol60_front08 --note switch_gan_front -g 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 8/70 [27:24<3:11:31, 185.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python train.py --train switch_gan02_tol65_front08 --note switch_gan_front -g 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 9/70 [27:45<2:15:58, 133.74s/it].33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python train.py --train switch_gan02_tol70_front08 --note switch_gan_front -g 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training:   4%|▎         | 14/400 [00:45<20:58,  3.26s/it]Traceback (most recent call last):\n",
      "  File \"/home/zhangyixiang/wfp/train.py\", line 94, in <module>\n",
      "    attack.train(\n",
      "  File \"/home/zhangyixiang/wfp/attack/base.py\", line 115, in train\n",
      "    net.to(device)\n",
      "  File \"/home/zhangyixiang/miniconda3/envs/wfp/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1152, in to\n",
      "    return self._apply(convert)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zhangyixiang/miniconda3/envs/wfp/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 802, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/zhangyixiang/miniconda3/envs/wfp/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 802, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/zhangyixiang/miniconda3/envs/wfp/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 825, in _apply\n",
      "    param_applied = fn(param)\n",
      "                    ^^^^^^^^^\n",
      "  File \"/home/zhangyixiang/miniconda3/envs/wfp/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1150, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "training:  52%|█████▏    | 207/400 [12:00<11:12,  3.48s/it]\n",
      "training:  63%|██████▎   | 253/400 [14:01<08:08,  3.33s/it]\n",
      " 14%|█▍        | 10/70 [42:17<6:01:38, 361.64s/it]2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python train.py --train switch_gan02_tol75_front08 --note switch_gan_front -g 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 11/70 [42:37<4:12:52, 257.16s/it]2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python train.py --train switch_gan02_tol80_front08 --note switch_gan_front -g 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training:  70%|███████   | 281/400 [14:59<06:21,  3.20s/it]\n",
      " 17%|█▋        | 12/70 [42:57<2:58:53, 185.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python train.py --train switch_gan02_tol85_front08 --note switch_gan_front -g 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 13/70 [43:17<2:08:22, 135.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python train.py --train switch_gan02_tol90_front08 --note switch_gan_front -g 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training:   4%|▎         | 14/400 [00:40<21:41,  3.37s/it]Traceback (most recent call last):\n",
      "  File \"/home/zhangyixiang/wfp/train.py\", line 94, in <module>\n",
      "    attack.train(\n",
      "  File \"/home/zhangyixiang/wfp/attack/base.py\", line 115, in train\n",
      "    net.to(device)\n",
      "  File \"/home/zhangyixiang/miniconda3/envs/wfp/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1152, in to\n",
      "    return self._apply(convert)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zhangyixiang/miniconda3/envs/wfp/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 802, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/zhangyixiang/miniconda3/envs/wfp/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 802, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/zhangyixiang/miniconda3/envs/wfp/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 825, in _apply\n",
      "    param_applied = fn(param)\n",
      "                    ^^^^^^^^^\n",
      "  File \"/home/zhangyixiang/miniconda3/envs/wfp/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1150, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "training:  64%|██████▍   | 257/400 [15:00<08:20,  3.50s/it]\n",
      "training:  63%|██████▎   | 253/400 [14:50<08:37,  3.52s/it]\n",
      "training:  68%|██████▊   | 274/400 [15:30<07:07,  3.39s/it]\n",
      " 20%|██        | 14/70 [59:10<5:56:28, 381.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python train.py --train switch_gan02_tol95_front08 --note switch_gan_front -g 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 15/70 [59:30<4:10:09, 272.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python train.py --train switch_gan04_tol30_front06 --note switch_gan_front -g 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 16/70 [59:50<2:57:08, 196.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python train.py --train switch_gan04_tol35_front06 --note switch_gan_front -g 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 17/70 [1:00:10<2:06:58, 143.74s/it]s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python train.py --train switch_gan04_tol40_front06 --note switch_gan_front -g 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training:   2%|▏         | 7/400 [00:24<21:25,  3.27s/it]]Traceback (most recent call last):\n",
      "  File \"/home/zhangyixiang/wfp/train.py\", line 94, in <module>\n",
      "    attack.train(\n",
      "  File \"/home/zhangyixiang/wfp/attack/base.py\", line 115, in train\n",
      "    net.to(device)\n",
      "  File \"/home/zhangyixiang/miniconda3/envs/wfp/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1152, in to\n",
      "    return self._apply(convert)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/zhangyixiang/miniconda3/envs/wfp/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 802, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/zhangyixiang/miniconda3/envs/wfp/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 802, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/home/zhangyixiang/miniconda3/envs/wfp/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 825, in _apply\n",
      "    param_applied = fn(param)\n",
      "                    ^^^^^^^^^\n",
      "  File \"/home/zhangyixiang/miniconda3/envs/wfp/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1150, in convert\n",
      "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: CUDA error: out of memory\n",
      "CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\n",
      "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
      "Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\n",
      "training:  44%|████▎     | 174/400 [10:08<13:09,  3.49s/it]\n",
      "training:  62%|██████▏   | 249/400 [13:30<08:11,  3.25s/it]\n",
      " 26%|██▌       | 18/70 [1:14:22<5:08:59, 356.54s/it]03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python train.py --train switch_gan04_tol45_front06 --note switch_gan_front -g 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training:  70%|██████▉   | 279/400 [14:26<04:09,  2.06s/it]"
     ]
    }
   ],
   "source": [
    "for task in tqdm(tasks):\n",
    "    while (gpu := get_avail_gpu()) is None:\n",
    "        pass\n",
    "    print(f\"python train.py --train {task} --note {note} -g {gpu}\")\n",
    "    subprocess.Popen(f\"python train.py --train {task} --note {note} -g {gpu}\", shell=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wfp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
