{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import dataset\n",
    "from defense import *\n",
    "from attack import RF\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "data = np.load(\"data/extracted/gpts.npz\", allow_pickle=True)\n",
    "traces, labels = data[\"traces\"], data[\"labels\"]\n",
    "root = Path(\"data/wang/gpts\")\n",
    "label2idx = json.load(open(\"data/wflibdata/gpts_full_info.json\"))\n",
    "label_count_dict = {}\n",
    "for i in range(len(traces)):\n",
    "    trace, label = traces[i], labels[i]\n",
    "    if label in label_count_dict:\n",
    "        idx = label_count_dict[label]\n",
    "        label_count_dict[label] += 1\n",
    "    else:\n",
    "        idx = 0\n",
    "        label_count_dict[label] = 1\n",
    "\n",
    "    trace_file = root / f\"{label2idx[label]}-{idx}\"\n",
    "    with open(trace_file, \"w\") as f:\n",
    "        trace[:, 0] = trace[:, 0] - trace[0, 0]\n",
    "        for cell in trace:\n",
    "            f.write(f\"{float(cell[0]):.5f}\\t{int(cell[1]*cell[2])}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regulator4 [0.23081952414915408, 0.6994640797567464]\n"
     ]
    }
   ],
   "source": [
    "ds = dataset.get_ds(\"df\")\n",
    "for defense in [\n",
    "    Empty(),\n",
    "    Front({\"client_dummy_pkt_num\": 4250, \"server_dummy_pkt_num\": 4250}, name=\"front_4250\"),\n",
    "    Tamaraw({\"client_interval\": 0.02, \"server_interval\": 0.006}, name=\"tamaraw_2_6\"),\n",
    "    Wfgan({\"tol\": 0.6}, name=\"gan300_tol6\"),\n",
    "    RegulaTor(\n",
    "        param={\n",
    "            \"orig_rate\": 350,\n",
    "            \"depreciation_rate\": 0.94,\n",
    "            \"burst_threshold\": 3.55,\n",
    "            \"upload_ratio\": 2.6,\n",
    "            \"delay_cap\": 1.77,\n",
    "        }\n",
    "    ),\n",
    "]:\n",
    "    ds.load_defended(defense, parallel=100)\n",
    "    ds.to_wang_format(defense)\n",
    "ds.load_defended(\n",
    "    Pred({\"security\": 0.7, \"data_vs_time\": 2}, name=\"pred300_security_7_data_vs_time_20\"),\n",
    "    parallel=100,\n",
    ")\n",
    "ds.to_wang_format(\"pred300_security_7_data_vs_time_20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import attack as wfpattack\n",
    "from config import *\n",
    "import numpy as np\n",
    "import dataset\n",
    "from defense import *\n",
    "from attack import RF\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "def get_cache(name, scenario, attack, defense):\n",
    "    ds = dataset.get_ds(name, scenario=scenario)\n",
    "    ds.load_defended(defense)\n",
    "    attack = wfpattack.get_attack(attack)\n",
    "    ds.get_cached_data(attack(10000, ds.num_classes(), 2))\n",
    "\n",
    "\n",
    "defenses = []\n",
    "for config in configs:\n",
    "    defenses.append(Customized(config[\"client\"], config[\"server\"], config[\"name\"], mode=\"moderate\"))\n",
    "for config in configs:\n",
    "    defenses.append(\n",
    "        Customized(config[\"client\"], config[\"server\"], config[\"name\"], mode=\"moderate25\")\n",
    "    )\n",
    "\n",
    "for name in [\"ours\", \"df\"]:\n",
    "    for scenario in [\"open-world\", \"closed-world\"]:\n",
    "        ds = dataset.get_ds(name, scenario=scenario)\n",
    "        for attack in [\"RF\", \"DF\"]:\n",
    "            attack = wfpattack.get_attack(attack)\n",
    "            for defense in defenses:\n",
    "                ds.load_defended(defense)\n",
    "                ds.get_cached_data(attack(10000, ds.num_classes(), 2, n_jobs=60))\n",
    "# Parallel(n_jobs=5)(delayed(get_cache)(name) for name in [\"ours\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
