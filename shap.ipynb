{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import attack as wfpattack\n",
    "from argparser import shap_parser\n",
    "from dataset import TraceDataset\n",
    "import joblib\n",
    "import torch\n",
    "import shap\n",
    "from tqdm import tqdm\n",
    "\n",
    "# prase arguments\n",
    "# args = shap_parser().parse_args()\n",
    "random_seed = 11\n",
    "ds_root = \"./data\"\n",
    "cache_root = \"./data/cache\"\n",
    "# attack_name = args.attack\n",
    "# note = args.note\n",
    "# train = args.train\n",
    "# dataset = args.dataset\n",
    "# model_epoch = args.epoch\n",
    "attack_name = \"RF\"\n",
    "note = \"20240307base\"\n",
    "train = \"undefend\"\n",
    "dataset = \"undefend\"\n",
    "model_epoch = 0\n",
    "model_dir = f\"data/dump/{note}/{attack_name}/train_{dataset}_d{train}\"\n",
    "assert os.path.exists(model_dir), model_dir\n",
    "\n",
    "print(\"Loading test dataset...\")\n",
    "test_ds = TraceDataset(dataset, ds_root)\n",
    "test_ds.load_defended_by_name(train)\n",
    "num_classes = test_ds.num_classes()\n",
    "attack: wfpattack.DNNAttack = wfpattack.get_attack(attack_name)(10000, num_classes, 0)\n",
    "\n",
    "\n",
    "ds_len = len(test_ds)\n",
    "\n",
    "_, evaluate_slice = train_test_split(\n",
    "    [i for i in range(ds_len)], test_size=0.2, random_state=random_seed\n",
    ")\n",
    "\n",
    "\n",
    "def get_cached_data(ds, attack, evaluate_slice):\n",
    "    global cache_root\n",
    "    cache_path = os.path.join(cache_root, f\"{attack.name}_{ds.get_hash()}.pkl\")\n",
    "    if os.path.exists(cache_path):\n",
    "        all_data = joblib.load(cache_path)\n",
    "        return {\n",
    "            \"traces\": all_data[\"traces\"][evaluate_slice],\n",
    "            \"labels\": all_data[\"labels\"][evaluate_slice],\n",
    "        }\n",
    "    else:\n",
    "        data = attack.data_preprocess(*ds[evaluate_slice])\n",
    "        return data\n",
    "\n",
    "\n",
    "print(\"Preparing test data...\")\n",
    "\n",
    "test_data = get_cached_data(test_ds, attack, evaluate_slice)\n",
    "test_features, test_labels = test_data[\"traces\"], test_data[\"labels\"]\n",
    "\n",
    "attack.init_model()\n",
    "print(\"Evaluating...\")\n",
    "result = attack.evaluate(\n",
    "    test_features,\n",
    "    test_labels,\n",
    "    load_dir=model_dir,\n",
    "    epoch=model_epoch,\n",
    "    data=True,\n",
    ")\n",
    "assert isinstance(result, tuple) and len(result) == 3\n",
    "metrics_dict, y_true, y_pred = result\n",
    "y_true = y_true.argmax(axis=1)\n",
    "y_pred = y_pred.argmax(axis=1)\n",
    "good_features = test_features[y_true == y_pred]\n",
    "good_labels = test_labels[y_true == y_pred]\n",
    "good_labels_int = good_labels.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_traces = []\n",
    "test_traces = {}\n",
    "for label in range(num_classes):\n",
    "    traces = good_features[good_labels_int == label]\n",
    "    bg_traces.append(traces[:2])\n",
    "    test_traces[label] = traces[2:]\n",
    "bg_traces = torch.cat(bg_traces, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "device = attack.device\n",
    "model = attack.model\n",
    "model.eval()\n",
    "explainer = shap.DeepExplainer(model, bg_traces.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer.shap_values(test_traces[0][:1, :].to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = []\n",
    "for label in tqdm(range(num_classes)):\n",
    "    cur_shap_values = explainer.shap_values(\n",
    "        test_traces[label], ranked_outputs=1, output_rank_order=\"max\"\n",
    "    )[0][0].squeeze()\n",
    "    shap_values.append(cur_shap_values.sum(axis=0).sum(axis=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
